import torch
from torch import nn
import collections
import sys

DATASET_PATH=sys.argv[1]
LOAD_PATH=sys.argv[2]
DUMP_PATH=sys.argv[3]


def main():
    # 载入数据集
    with open(DATASET_PATH, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        raw_dataset = [i.split() for i in lines]

    # 句尾符为 '' ，生僻词全用 '' 表示，数字则被替换成了 'N'
    '''
    for st in raw_dataset[:5]:
        print("# token",len(st),st[:5])
    '''

    # 建立词语索引
    counter = collections.Counter([tk for st in raw_dataset for tk in st])  # tk是token的缩写
    counter = dict(filter(lambda x: x[1] >= 5, counter.items()))  # 只保留在数据集中至少出现5次的词

    idx_to_token = [tk for tk, _ in counter.items()]
    token_to_idx = {tk: idx for idx, tk in enumerate(idx_to_token)}

    # 模型读取
    net=torch.load(LOAD_PATH)

    word_vector=net[0].weight

    with open(DUMP_PATH,'w',encoding='utf-8') as f:
        for key,value in token_to_idx.items():
            f.write(key+" "+str(' '.join([str(i) for i in word_vector[value].tolist()])))
            f.write('\n')


if __name__=="__main__":
    main()