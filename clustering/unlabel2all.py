import pathlib
import json
import os
from sklearn.model_selection import train_test_split

def unlabel2all(source_path, target1_path,target2_path):
    source_path = pathlib.Path(source_path)
    word_path = pathlib.Path(target1_path)
    DNN_path=pathlib.Path(target2_path)

    text = []

    source=[]
    for file in os.listdir(source_path):
        source.append(source_path.joinpath(file))

    X=[]
    y=[]
    for i in source:
        with open(i,'r',encoding='utf-8') as f:
            label=0
            if "black" in str(i):
                label=1
            for line in f.readlines():
                sequence=json.loads(line)
                for j in range(len(sequence)):
                    sequence[j]=sequence[j].replace('Fake_', '')
                    m=sequence[j].find('(')
                    if m!=-1:
                        sequence[j]=sequence[j][:m]
                X.append(sequence)
                y.append(label)

    with open(word_path,'w',encoding='utf-8') as f:
        for t in X:
            f.write(' '.join(t))
            f.write('\n')

    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.5, random_state=2022, stratify=y)

    train = []
    for text, label in zip(X_train, Y_train):
        temp = {}
        temp['text'] = ' '.join(text)
        temp['label'] = label
        train.append(temp)

    test = []
    for text, label in zip(X_test, Y_test):
        temp = {}
        temp['text'] = ' '.join(text)
        temp['label'] = label
        test.append(temp)

    with open(DNN_path.joinpath("unlabel_train.json"), 'w', encoding='utf-8') as f:
        for i in train:
            f.write(json.dumps(i, ensure_ascii=False))
            f.write('\n')

    with open(DNN_path.joinpath("unlabel_test.json"), 'w', encoding='utf-8') as f:
        for i in test:
            f.write(json.dumps(i, ensure_ascii=False))
            f.write('\n')






if __name__ == "__main__":
    unlabel2all("../data/", "../word2vec/unlabel_embedding.txt","../DNN/DNN_data/")