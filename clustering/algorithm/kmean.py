from sklearn.cluster import KMeans
import joblib
from sklearn.datasets import make_blobs
import random


def save_KMeans(model, model_path):
    joblib.dump(model, model_path)


def load_KMeans(model_path):
    return joblib.load(model_path)


class K_Means():
    """
    n_cluster: The number of clusters to form as well as the number of centroids to generate.
    init: Method for initialization.
    n_init: Number of times the k-means algorithm is run with different centroid seeds.
    max_iter: Maximum number of iterations of the k-means algorithm for a single run.
    tol: Relative tolerance with regards to Frobenius norm of the difference in the cluster centers of two consecutive iterations to declare convergence.
    verbose: Verbosity mode.
    random_state: Determines random number generation for centroid initialization. Use an int to make the randomness deterministic.
    copy_x: When pre-computing distances it is more numerically accurate to center the data first. If copy_x is True (default), then the original data is not modified.
    algorithm: K-means algorithm to use.
    """

    def __init__(self, n_clusters, init="k-means++", n_init=10, max_iter=300, tol=0.0001,
                 verbose=0, random_state=None, copy_x=True, algorithm='lloyd'):
        self.model = KMeans(n_clusters, init=init, n_init=n_init, max_iter=max_iter, tol=tol,
                            verbose=verbose, random_state=random_state,
                            copy_x=copy_x, algorithm=algorithm)

    def fit(self, x):
        self.model.fit(x)

    def predict(self, x):
        return self.model.predict(x)


if __name__ == "__main__":
    X,y=make_blobs(n_samples=800,n_features=5,centers=3,random_state=2023)
    idx=[i for i in range(800)]
    random.shuffle(idx)
    model=K_Means(3)
    model.fit(X[idx])

    save_KMeans(model,'kmeans.joblib')

    new_model=load_KMeans('kmeans.joblib')
    pre=new_model.predict(X[idx[600:]])
    print(y[idx[600:]]==pre)
