import torch
import random
import numpy as np
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import matplotlib.pyplot as plt
import torch.utils.data as Data
from BiLSTM import BiLSTM_Attention
from torchtext import data
from torchtext.vocab import Vectors
from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score,roc_curve,auc
import time
import pickle

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

SEED=2023
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

'''
vector_path="../../word2vec/vector/native_vector_embed_3_new.txt"
train_path="../DNN_data/train_CLUSTER_3.json"
test_path="../DNN_data/test_CLUSTER_3.json"
'''

'''
vector_path="../../word2vec/vector/native_vector_embed_4.txt"
train_path="../DNN_data/train_CLUSTER_4.json"
test_path="../DNN_data/test_CLUSTER_4.json"
'''


vector_path="../../word2vec/vector/native_vector_embed_5_new.txt"
train_path="../DNN_data/train_CLUSTER_5.json"
test_path="../DNN_data/test_CLUSTER_5.json"


'''
vector_path="../../word2vec/vector/native_vector_embed_6.txt"
train_path="../DNN_data/train_CLUSTER_6.json"
test_path="../DNN_data/test_CLUSTER_6.json"
'''

'''
vector_path="../../word2vec/vector/native_vector_embed_unlabel.txt"
train_path="../DNN_data/unlabel_train.json"
test_path="../DNN_data/unlabel_test.json"
'''

batch_size=64

'''
raw_database：
{'text':'api_label', 'label':'1'}
{'text':'api_label', 'label':'1'}
'''

def tokenizer(text):
    return text.split(' ')

stop_words = []  
text = data.Field(sequential=True,
                  fix_length=1000,
                  tokenize=tokenizer,
                  stop_words=stop_words)
label = data.Field(sequential=False)

# Database
train, test= data.TabularDataset.splits(
    path='../DNN_data/',
    skip_header=True,
    train=train_path,
    validation=test_path,
    #train='unlabel_train.json',
    #validation='unlabel_test.json',
    format='json',
    fields={'text':('text',text),'label':('label',label)},
)

text.build_vocab(train, test, vectors=Vectors(name=vector_path))
label.build_vocab(train, test)

embedding_dim = text.vocab.vectors.size()[-1]
vectors = text.vocab.vectors

# iterator
train_iter,test_iter = data.Iterator.splits(
            (train,test),
            sort_key=lambda x: len(x.text),
            batch_sizes=(batch_size,batch_size), # 训练集设置batch_size,验证集整个集合用于测试
            device=device
    )

vocab_size = len(text.vocab)
label_num = len(label.vocab)


'''
training
'''
def evalute_for_roc(data_iter,net):
    predict = []
    label = []
    n = 0
    with torch.no_grad():
        for batch_idx, batch in enumerate(data_iter):
            X, y = batch.text, batch.label
            y.data.sub_(1)
            label += y.cpu().detach().tolist()
            if isinstance(net, torch.nn.Module):
                net.eval()  
                # predict += net(X).softmax(dim=1)[:,1].cpu().detach().tolist()
                predict += net(X)[:, 1].cpu().detach().tolist()
                net.train()  
            else: 
                if ('is_training' in net.__code__.co_varnames):  
                    predict += net(X, is_training=False)[:, 1].cpu().detach().tolist()
                else:
                    predict += net(X)[:, 1].cpu().detach().tolist()
            n += y.shape[0]
    print(n)
    fpr,tpr,thresholds=roc_curve(label,predict,pos_label=1,drop_intermediate=False)
    return fpr,tpr,thresholds


# accuracy_score,precision_score,f1_score,recall_score
def evaluate_accuracy(data_iter, net):
    predict=[]
    label=[]
    n=0
    with torch.no_grad():
        for batch_idx, batch in enumerate(data_iter):
            X, y = batch.text, batch.label
            y.data.sub_(1)
            label+=y.cpu().detach().tolist()
            if isinstance(net, torch.nn.Module):
                net.eval()
                predict+=net(X).argmax(dim=1).cpu().detach().tolist()
                net.train() 
            else: 
                if('is_training' in net.__code__.co_varnames): 
                    predict += net(X,is_training=False).argmax(dim=1).cpu().detach().tolist()
                else:
                    predict += net(X).argmax(dim=1).cpu().detach().tolist()
            n += y.shape[0]
    print(n)
    return accuracy_score(label,predict),precision_score(label,predict,average="macro"),f1_score(label,predict,average="macro"),recall_score(label,predict,average="macro")


def training(train_iter, test_iter, net, loss, optimizer, num_epochs,max_f1):
    batch_count = 0
    val_iter=[]
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()
        for batch_idx, batch in enumerate(train_iter):
            if batch_idx in val_batch:
                val_iter.append(batch)
                continue
            X, y = batch.text, batch.label
           # X = X.permute(1, 0)
            y.data.sub_(1)
            y_hat = net(X)
            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
            n += y.shape[0]
            batch_count += 1

        accuracy, precision, f1, recall = evaluate_accuracy(val_iter, net)
        print(
            "loss： %.4f, train acc： %.5f, val acc： %.5f, val precision： %.5f, val f1_score： %.5f, val recall： %.5f, time： %.1f sec"
            % (train_l_sum / batch_count, train_acc_sum / n,
               accuracy, precision, f1, recall, time.time() - start))

        accuracy, precision, f1, recall= evaluate_accuracy(test_iter, net)
        if f1>max_f1:
            max_f1=f1
            torch.save(model,"Bi-LSTM.pth")
        print(
             "test acc： %.5f, test precision： %.5f, f1_score： %.5f, recall： %.5f"
            % ( accuracy, precision, f1, recall))

        fpr, tpr, thresholds = evalute_for_roc(test_iter, net)
        a = auc(fpr, tpr)
        plt.figure()
        lw = 2
        plt.plot(fpr, tpr, color='darkorange',
                 lw=lw, label='ROC curve (area = %0.4f)' % a)
        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver operating characteristic example')
        plt.legend(loc="lower right")
        filename = 'roc/lstm_roc' + str(time.time() * 100)
        with open(filename + '.pickle', 'wb') as f:
            pickle.dump([fpr, tpr, a], f)
        plt.savefig(filename + '.png')
    return max_f1


EPOCH=1
n_hidden = 64  # number of hidden units in one cell
n_layer=3
num_classes = label_num
lr=0.001

model = BiLSTM_Attention(vocab_size,embedding_dim,n_hidden,n_layer,num_classes,vectors).to(device)
print(model)
criterion = nn.CrossEntropyLoss().to(device)
optimizer = optim.Adam(model.parameters(), lr=lr)


# K-fold cross-validation
K=5
max_f1=0
for epoch in range(EPOCH):
    for i in range(K):
        print('第 '+str(i+1)+" fold:")
        fold_len=len(train_iter)/K
        val_batch=range(int(fold_len*i),int(fold_len*(i+1)))
        max_f1=training(train_iter, test_iter, model, criterion, optimizer, 1, max_f1)

