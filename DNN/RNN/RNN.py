import torch
import torch.nn as nn
import torch.nn.functional as F

class RNN(nn.Module):
    def __init__(self, vocab_size, embedding_dim, num_hiddens, num_layers,output_dim,vectors):
        super(RNN, self).__init__()
        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)
        self.word_embeddings = self.word_embeddings.from_pretrained(
            vectors, freeze=True)
        self.encoder=nn.RNN(input_size=embedding_dim,hidden_size=num_hiddens,num_layers=num_layers,batch_first=False,bidirectional=False)
        self.dropout=nn.Dropout(p=0.2)
        # self.linear=nn.Linear(num_hiddens*2,output_dim)
        self.linear = nn.Linear(num_hiddens, output_dim)

    def forward(self, inputs):
        # inputs的形状是(seq_len,batch_size)
        embeddings = self.word_embeddings(inputs)
        outputs,_ = self.encoder(embeddings)
        # outputs形状是(seq_len,batch_size, 2 * num_hiddens)
        outputs = outputs.permute(1, 0, 2)
        # x形状是(batch_size, seq_len, 2 * num_hiddens)
        outputs = torch.mean(outputs,dim=1)
        return self.linear(self.dropout(outputs))